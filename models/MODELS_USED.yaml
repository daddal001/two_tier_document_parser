# Model Provenance and Registry
#
# This file tracks all ML models used in the Two-Tier Document Parser for:
# - Reproducibility: Exact versions and checksums ensure consistent results
# - Security: Verify model integrity and detect tampering
# - Compliance: Audit trail for model lineage and licensing
# - Documentation: Clear record of what models power the system
#
# Format:
#   - name: Human-readable model name
#     repository: HuggingFace repository ID
#     revision: Git tag, branch, or commit SHA
#     purpose: What this model does
#     license: Model license
#     size: Approximate download size
#     files: List of model files with checksums
#     notes: Additional information

models:
  # =============================================================================
  # Layout Detection Models
  # =============================================================================

  - name: LayoutLMv3 Base
    repository: microsoft/layoutlmv3-base
    revision: main
    purpose: Document layout analysis and structure detection
    license: MIT
    size: ~500 MB
    performance:
      accuracy: ~92% on DocVQA
      speed: ~100ms per page
    files:
      - name: pytorch_model.bin
        sha256: "TO_BE_FILLED_AFTER_DOWNLOAD"
        size: 469MB
      - name: config.json
        sha256: "TO_BE_FILLED_AFTER_DOWNLOAD"
    usage: Used by MinerU for initial document layout understanding
    notes: |
      Pre-trained on large-scale document datasets.
      Fine-tuned for form understanding and visual question answering.

  # =============================================================================
  # OCR Models
  # =============================================================================

  - name: PaddleOCR v4
    repository: paddlepaddle/PaddleOCR
    revision: release/2.7
    purpose: Optical Character Recognition for text extraction
    license: Apache-2.0
    size: ~200 MB
    performance:
      accuracy: ~95% on standard documents
      speed: ~50ms per page
    languages:
      - English
      - Chinese (Simplified & Traditional)
      - Japanese
      - Korean
      - 80+ languages supported
    files:
      - name: en_PP-OCRv4_det_infer.tar
        sha256: "TO_BE_FILLED_AFTER_DOWNLOAD"
      - name: en_PP-OCRv4_rec_infer.tar
        sha256: "TO_BE_FILLED_AFTER_DOWNLOAD"
    usage: Primary OCR engine for text recognition in MinerU
    notes: |
      Supports both detection and recognition models.
      Optimized for production deployment.

  # =============================================================================
  # Vision Language Models (VLM)
  # =============================================================================

  - name: Qwen2-VL-7B
    repository: Qwen/Qwen2-VL-7B-Instruct
    revision: main
    purpose: Vision-language understanding for complex document elements
    license: Apache-2.0
    size: ~15 GB
    performance:
      accuracy: ~95% on DocVQA
      speed: ~15-60s per page (GPU-dependent)
    requirements:
      min_vram: 16 GB
      recommended_vram: 24 GB
      cuda: ">=11.8"
      transformers: ">=4.51.1"
    files:
      - name: model-00001-of-00004.safetensors
        sha256: "TO_BE_FILLED_AFTER_DOWNLOAD"
        size: 4.95GB
      - name: model-00002-of-00004.safetensors
        sha256: "TO_BE_FILLED_AFTER_DOWNLOAD"
        size: 4.95GB
      - name: model-00003-of-00004.safetensors
        sha256: "TO_BE_FILLED_AFTER_DOWNLOAD"
        size: 4.95GB
      - name: model-00004-of-00004.safetensors
        sha256: "TO_BE_FILLED_AFTER_DOWNLOAD"
        size: 1.01GB
      - name: config.json
        sha256: "TO_BE_FILLED_AFTER_DOWNLOAD"
      - name: generation_config.json
        sha256: "TO_BE_FILLED_AFTER_DOWNLOAD"
    usage: Used for high-accuracy parsing of tables, formulas, and images
    notes: |
      Requires transformers>=4.51.1 for Qwen2VLForConditionalGeneration.
      Best results with GPU (Tesla T4, RTX 3090, A100).
      Automatic CPU fallback available (slower, ~80-85% accuracy).

  # =============================================================================
  # Table Recognition Models
  # =============================================================================

  - name: TableMaster
    repository: microsoft/table-transformer-detection
    revision: main
    purpose: Table structure recognition and cell detection
    license: MIT
    size: ~300 MB
    performance:
      accuracy: ~96% on PubTables-1M
      speed: ~200ms per table
    files:
      - name: pytorch_model.bin
        sha256: "TO_BE_FILLED_AFTER_DOWNLOAD"
      - name: config.json
        sha256: "TO_BE_FILLED_AFTER_DOWNLOAD"
    usage: Specialized model for detecting and parsing table structures
    notes: |
      Trained on PubTables-1M dataset.
      Handles complex multi-row/column spans.

  # =============================================================================
  # Formula Recognition Models
  # =============================================================================

  - name: UniMERNet
    repository: wanderkid/unimernet
    revision: main
    purpose: Mathematical formula recognition (OCR for LaTeX)
    license: MIT
    size: ~400 MB
    performance:
      accuracy: ~92% on mathematical formulas
      speed: ~100ms per formula
    files:
      - name: pytorch_model.bin
        sha256: "TO_BE_FILLED_AFTER_DOWNLOAD"
    usage: Converts mathematical notation images to LaTeX
    notes: |
      Handles complex mathematical expressions.
      Outputs LaTeX format for downstream processing.

# =============================================================================
# Model Download and Verification
# =============================================================================

download_instructions: |
  Models are automatically downloaded on first use via MinerU's model manager.

  Manual download and verification:

  1. Download models:
     mineru-models-download -s huggingface -m all

  2. Verify checksums (example):
     sha256sum ~/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/*/model-*.safetensors

  3. Update this file with actual checksums for your deployment.

  4. In production, verify checksums before deployment:
     python scripts/verify_models.py

checksum_generation: |
  To generate checksums for downloaded models:

  find ~/.cache/huggingface/hub -name "*.safetensors" -o -name "*.bin" | while read file; do
    echo "$(sha256sum "$file" | cut -d' ' -f1) - $(basename "$file")"
  done

# =============================================================================
# Model Selection and Configuration
# =============================================================================

model_selection:
  fast_parser:
    - PyMuPDF (built-in, no external models)
    - Pure text extraction, no ML models
    - Fastest option, lowest resource requirements

  accurate_parser_cpu:
    - LayoutLMv3: Layout detection
    - PaddleOCR: Text recognition
    - TableMaster: Table structure
    - UniMERNet: Formula recognition
    - Pipeline mode: 80-85% accuracy
    - Resource: 8-16GB RAM

  accurate_parser_gpu:
    - All CPU models PLUS:
    - Qwen2-VL-7B: Vision-language understanding
    - VLM mode: 95%+ accuracy
    - Resource: 16GB+ VRAM, 16GB+ RAM

# =============================================================================
# Model Update Policy
# =============================================================================

update_policy: |
  Models are pinned to specific versions for reproducibility.
  Updates are tested thoroughly before deployment.

  Update process:
  1. Test new model version in staging environment
  2. Run accuracy benchmarks against test set
  3. Update this file with new versions and checksums
  4. Update CHANGELOG.md with model version changes
  5. Tag new release with model version updates

last_updated: "2024-11-23"
maintained_by: "Two-Tier Parser Team"
audit_schedule: "Quarterly"

# =============================================================================
# Licensing and Attribution
# =============================================================================

license_compliance: |
  All models used are compatible with AGPL-3.0 license.
  Commercial use requires verification of individual model licenses.

  Key licenses:
  - MIT: Permissive, commercial-friendly
  - Apache-2.0: Permissive, patent grant included

  See NOTICE file for full attribution.

attribution: |
  This project uses models from:
  - Microsoft Research (LayoutLMv3, TableMaster)
  - Alibaba Cloud (Qwen2-VL)
  - PaddlePaddle (PaddleOCR)
  - Community contributors (UniMERNet)

  We are grateful to these organizations and researchers for open-sourcing their work.

# =============================================================================
# Security and Privacy
# =============================================================================

security_notes: |
  - Models are downloaded from official HuggingFace repositories
  - Use HF_TOKEN with read-only permissions
  - Verify checksums in production deployments
  - Models process data locally (no external API calls)
  - No telemetry or data collection by models
  - Comply with your organization's model governance policies

privacy_compliance: |
  - Models run entirely on-premises
  - No data sent to external services
  - Suitable for processing sensitive documents
  - GDPR compliant (data processed locally)
  - HIPAA considerations: suitable for healthcare if properly deployed

# =============================================================================
# Performance Tuning
# =============================================================================

performance_notes: |
  - VLM models benefit from float16/bfloat16 precision
  - Batch processing improves throughput
  - Model compilation (torch.compile) can improve speed
  - Quantization (int8/int4) reduces VRAM usage
  - Consider model caching and warming for production

recommended_hardware:
  fast_parser:
    cpu: "4 cores"
    ram: "4 GB"

  accurate_parser_cpu:
    cpu: "4-8 cores"
    ram: "16 GB"

  accurate_parser_gpu:
    gpu: "NVIDIA Tesla T4 / RTX 3090 / A100"
    vram: "16-24 GB"
    ram: "16 GB"
    cuda: "11.8 or 12.1"
